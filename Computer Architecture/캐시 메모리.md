# 캐시 메모리란?

- 속도가 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리

> ex1) CPU 코어와 메모리 사이의 병목 현상 완화 ex2) 웹 브라우저 캐시 파일은, 하드디스크와 웹페이지 사이의 병목 현상을 완화

- CPU가 주기억 장치에서 데이터를 읽어와 캐시 메모리에 저장 → 이후 캐시메모리에서 먼저 가져오면서 속도 향상
- 속도와 크기에 따라 L1, L2, L3 캐시 메모리 존재 (L1 → L2 → L3 순서로 탐색)
    - 캐시 메모리 종류
        - L1 : CPU 내부에 존재
        - L2 : CPU와 RAM 사이에 존재
        - L3 : 보통 메인보드에 존재한다고 함
- 용량이 적고 비쌈

> _**듀얼 코어 프로세서의 캐시 메모리**_ 각 코어마다 독립된 L1 캐시 메모리를 가지고, 두 코어가 공유하는 L2 캐시 메모리가 내장됨

# 작동 원리

- **시간 지역성**
    
    한번 참조된 데이터는 잠시후 또 참조될 가능성이 높음
    
- **공간 지역성**
    
    A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높음
    

> 이처럼 참조 지역성의 원리가 존재

CPU가 요청한 데이터가 캐시에 있으면 '**Cache Hit**', 없어서 DRAM에서 가져오면 '**Cache Miss**'

## Cache Miss & 해결 방법

### 1. Compulsory Miss

**정의**

- cold start miss
- 데이터에 처음 접근시 캐시에 데이터를 올리기 위해 발생하는 캐시 미스

**해결 방법**

- **Prefetching**: 데이터나 명령어를 미리 캐시에 가져오는 방법. 프로세서가 특정 데이터에 접근할 것으로 예상되면, 미리 해당 데이터를 캐시로 가져옴.
- **Larger Block Size**: 더 큰 블록 크기를 사용하면 한 번에 더 많은 데이터를 캐시에 저장할 수 있어 초기 접근에서 발생하는 미스를 줄일 수 있음. 하지만 너무 큰 블록 크기는 다른 유형의 캐시 미스를 증가시킬 수 있음.

### 2. Capacity Miss

**정의**

- 캐시의 용량이 부족하여 발생하는 미스

**해결 방법**

- **Larger Cache Size**: 캐시의 크기를 늘리면 더 많은 데이터를 저장할 수 있어 캐시의 용량으로 인한 미스를 줄일 수 있음.
- **Victim Cache**: 메인 캐시에서 제거된 데이터를 임시로 저장하는 작은 캐시를 사용하여 제거된 데이터에 다시 접근할 때 미스를 줄임.

### 3. Conflict Miss

**정의**

- 두 개 이상의 데이터가 같은 캐시 라인을 사용하려 할 때 발생

**해결 방법**

- **Increased Associativity**: N-웨이 세트 연관 캐시(Set-Associative Cache)의 연관성을 높이면 서로 다른 메모리 주소가 같은 캐시 라인에 매핑되는 것을 줄임. 하지만 연관성이 높아질수록 캐시 접근 시간이 증가함.
- **Pseudo-Associative or Fully Associative Caches**: 이러한 캐시 유형은 더 유연한 데이터 저장을 허용. 하지만 구현이 복잡하고 비용이 더 많이 듦.
- **Optimized Memory Access Patterns**: 메모리 접근 패턴을 최적화하여 Conflict Misses를 줄일 수 있습니다. 예를 들어, 배열을 순회하는 방식을 변경하여 메모리 접근 패턴을 개선.

# 구조

## 1. Direct Mapped (직접 사상)

- **구조**: 각 메모리 주소는 캐시의 특정 라인에 직접 매핑. 메모리 주소의 일부 비트를 사용하여 결정.
- **작동 원리**: 메모리 주소의 특정 비트(예: 하위 비트)를 사용하여 해당 주소가 저장될 캐시 라인을 결정합니다. 메모리 주소는 이 비트를 기반으로 한 특정 라인에만 저장될 수 있으며, 이로 인해 다른 주소와 충돌이 발생할 수 있습니다.
- **장점**: 구현이 간단하고 빠른 캐시 탐색이 가능
- **단점**: Conflict Misses가 자주 발생

## **2. Set-Associative (집합 연관)**

- **구조**: 집합 연관 캐시는 캐시를 여러 "세트"로 나누며, 각 세트는 여러 개의 라인(즉, N-웨이)을 가짐
- **작동 원리**: 메모리 주소의 일부 비트를 사용하여 해당 주소가 매핑될 세트를 결정. 주소는 결정된 세트 내의 어느 라인에도 저장될 수 있음.
- **장점**: Conflict Misses를 줄일 수 있으며, 직접 사상 캐시에 비해 더 높은 캐시 히트율을 제공
- **단점**: 직접 사상 캐시보다 복잡하며, 더 많은 하드웨어 리소스가 필요.

## **3. Fully Associative (완전 연관)**

- **구조**: 완전 연관 캐시에서는 캐시의 모든 라인이 어떤 메모리 주소든지 저장할 수 있음. 메모리 주소는 캐시 내의 어느 위치에도 저장될 수 있으며, 세트나 특정 라인에 제한되지 않음.
- **작동 원리**: 메모리 주소의 태그를 캐시 내의 모든 라인의 태그와 비교하여 데이터를 찾음. 태그가 일치하는 라인이 있으면 캐시 히트가 발생.
- **장점**: Conflict Misses를 완전히 제거.
- **단점**: 모든 캐시 라인을 검색 하므로 탐색 시간이 길어짐. 높은 하드웨어 복잡성과 비용이 필요